{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "from ast import literal_eval"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('data/listings.csv.gz', index_col=0, compression='gzip', )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Drop Irrelevant Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Furthermore, remove features with more than 50% missing values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Features with more than 50% missing values:\\n{df.columns[df.isnull().mean() > .5]}\")\n",
    "\n",
    "df = df.dropna(thresh=.5*len(df), axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remove columns which hold only one unique value, making it redundant to include for training machine learning models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Features with only one unique value:\\n{df.columns[df.nunique() == 1]}\")\n",
    "\n",
    "df = df.loc[:,df.apply(pd.Series.nunique) != 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feats = [\n",
    "    'listing_url',\n",
    "    'last_scraped',\n",
    "    'source',\n",
    "    'name',\n",
    "    'description',\n",
    "    'picture_url',\n",
    "    'host_id',\n",
    "    'host_url',\n",
    "    'host_name',\n",
    "    'host_location',\n",
    "    'host_about',\n",
    "    'host_response_rate',\n",
    "    'host_acceptance_rate',\n",
    "    'host_thumbnail_url',\n",
    "    'host_picture_url',\n",
    "    'host_listings_count',\n",
    "    'host_verifications',\n",
    "    'latitude',\n",
    "    'longitude',\n",
    "    'property_type',\n",
    "    'bathrooms_text',\n",
    "    'bedrooms',\n",
    "    'minimum_minimum_nights',\n",
    "    'maximum_minimum_nights',\n",
    "    'minimum_maximum_nights',\n",
    "    'maximum_maximum_nights',\n",
    "    'minimum_nights_avg_ntm',\n",
    "    'maximum_nights_avg_ntm',\n",
    "    'availability_30',\n",
    "    'availability_60',\n",
    "    'availability_90',\n",
    "    'availability_365',\n",
    "    'calendar_last_scraped',\n",
    "    'number_of_reviews_ltm',\n",
    "    'number_of_reviews_l30d',\n",
    "    'last_review',\n",
    "    'review_scores_accuracy',\n",
    "    'review_scores_cleanliness',\n",
    "    'review_scores_checkin',\n",
    "    'review_scores_communication',\n",
    "    'review_scores_location',\n",
    "    'review_scores_value',\n",
    "    'calculated_host_listings_count',\n",
    "    'calculated_host_listings_count_entire_homes',\n",
    "    'calculated_host_listings_count_private_rooms',\n",
    "    'calculated_host_listings_count_shared_rooms',\n",
    "    ]\n",
    "df = df.drop(feats, axis=1)\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stardardizing and Formatting Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert the price from object to float"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['price'] = df['price'].str.replace('$', '').str.replace(',', '').astype(float)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert f/t entries to boolean [0, 1] entries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "boolean_cols = [\n",
    "    'host_is_superhost',\n",
    "    'host_has_profile_pic',\n",
    "    'host_identity_verified',\n",
    "    'instant_bookable'\n",
    "]\n",
    "\n",
    "m = {'t': True, 'f': False}\n",
    "\n",
    "for col in boolean_cols:\n",
    "    df[col] = df[col].map(m).astype(bool).astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert date strings to DateTime objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline_date = datetime(2025, 3, 1)\n",
    "\n",
    "date_cols = [\n",
    "    'host_since',\n",
    "    'first_review',\n",
    "]\n",
    "\n",
    "for col in date_cols:\n",
    "    df[col] = pd.to_datetime(df[col])\n",
    "    df[col] = (baseline_date - df[col]).dt.days"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert host_response_time into a numerical value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = {'within an hour': 1, 'within a few hours': 2, 'within a day': 3, 'a few days or more': 4}\n",
    "\n",
    "df['host_response_time'] = df['host_response_time'].map(m).astype(float)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert neighbourhood_cleansed and room_type to a numeric value through one-hot encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Neighbourhood\n",
    "dummies = pd.get_dummies(df['neighbourhood_cleansed']).astype(int)\n",
    "df = df.join(dummies)\n",
    "df.drop('neighbourhood_cleansed', axis=1, inplace=True)\n",
    "\n",
    "# Room type\n",
    "dummies = pd.get_dummies(df['room_type']).astype(int)\n",
    "df = df.join(dummies)\n",
    "df.drop('room_type', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert the list of amenities to a integer count of the list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['amenities'] = df['amenities'].apply(literal_eval).apply(len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Missing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remove all rows of data where the price is unknown, as these cannot be used to train or test a model to predict the price."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Number of rows containing no price: {df['price'].isnull().sum()}\")\n",
    "\n",
    "df = df.dropna(subset=['price'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remove duplicate entries from the DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Number of duplicate entries: {df.duplicated().sum()}\")\n",
    "\n",
    "df = df.drop_duplicates()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remove rows which have more than half of the features missing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Number of rows missing more than 50% of features: {df.isnull().mean(axis=1).gt(.5).sum()}\")\n",
    "\n",
    "df = df[df.isnull().mean(axis=1) < .5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df.isnull().sum().to_string())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Outliers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remove all rows where the price is higher than the 99th percentile. This is to remove faulty listings, which can negatively impact the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Number of outlier above 99th percentile: {len(df[df['price'] > df['price'].quantile(0.99)])}\")\n",
    "\n",
    "df = df[df['price'] < df['price'].quantile(0.99)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
